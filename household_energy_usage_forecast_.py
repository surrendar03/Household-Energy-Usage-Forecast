# -*- coding: utf-8 -*-
"""Household Energy Usage Forecast .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oeaY6InCHIMGGXiyv_NBwQ8_cJI_IP12
"""

import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_fwf("household_power_consumption.txt")

df

import pandas as pd
from io import StringIO

# Use StringIO to simulate reading from a file
data_io = StringIO(df)

# Read the data into a DataFrame
df1 = pd.read_csv(data_io, sep=';')

print(df1)

import pandas as pd
from io import StringIO

# Convert the DataFrame to a CSV string
csv_string = df.to_csv(index=False)

# Use StringIO to simulate reading from a file
data_io = StringIO(csv_string)

# Read the data into a DataFrame
df1 = pd.read_csv(data_io, sep=';')

print(df1)

df1

df=pd.read_csv('household_power_consumption.csv')

len(df1)

"""2075259"""

len(df)

df1.dtypes

df.head(

 )

(df1.isnull().sum()[df1.isnull().sum()>0]/len(df))*100

df1.duplicated().sum()

df1.columns



df1['Sub_metering_3'].replace('?', np.nan, inplace=True)
df1['Sub_metering_1'].replace('?', np.nan, inplace=True)
df1['Sub_metering_2'].replace('?', np.nan, inplace=True)
df1['Voltage'].replace('?', np.nan, inplace=True)
df1['Global_intensity'].replace('?', np.nan, inplace=True)
df1['Global_reactive_power'].replace('?', np.nan, inplace=True)
df1['Global_active_power'].replace('?', np.nan, inplace=True)
df1['Time'].replace('00:00:00', np.nan, inplace=True)

df1.columns

df1.dtypes

df1["Date"]

df1['Date'] = pd.to_datetime(df1['Date'], format='%d-%m-%Y')
df1['Sub_metering_3']=pd.to_numeric(df1['Sub_metering_3'], errors='coerce')
df1['Sub_metering_1']= pd.to_numeric(df1['Sub_metering_1'], errors='coerce')
df1['Sub_metering_2']= pd.to_numeric(df1['Sub_metering_2'], errors='coerce')
df1['Voltage']= pd.to_numeric(df1['Voltage'], errors='coerce')
df1['Global_intensity']= pd.to_numeric(df1['Global_intensity'], errors='coerce')
df1['Global_reactive_power']= pd.to_numeric(df1['Global_reactive_power'], errors='coerce')
df1['Global_active_power']= pd.to_numeric(df1['Global_active_power'], errors='coerce')
df1['Time']= pd.to_datetime(df1['Time'], format='%H:%M:%S')

df1['Date'] = pd.to_datetime(df1['Date'], format='%d/%m/%Y') # Change the format string to '%d/%m/%Y' to match the actual date format
df1['Sub_metering_3']=pd.to_numeric(df1['Sub_metering_3'], errors='coerce')
df1['Sub_metering_1']= pd.to_numeric(df1['Sub_metering_1'], errors='coerce')
df1['Sub_metering_2']= pd.to_numeric(df1['Sub_metering_2'], errors='coerce')
df1['Voltage']= pd.to_numeric(df1['Voltage'], errors='coerce')
df1['Global_intensity']= pd.to_numeric(df1['Global_intensity'], errors='coerce')
df1['Global_reactive_power']= pd.to_numeric(df1['Global_reactive_power'], errors='coerce')
df1['Global_active_power']= pd.to_numeric(df1['Global_active_power'], errors='coerce')
df1['Time']= pd.to_datetime(df1['Time'], format='%H:%M:%S')

#df['Time'].fillna(df['Time'].mode(), inplace=True)
df1['Time'].fillna(df1['Time'].mode()[0], inplace=True)
df1['Global_active_power'].fillna(df1['Global_active_power'].median(), inplace=True)
df1['Global_reactive_power'].fillna(df1['Global_reactive_power'].median(), inplace=True)
df1['Voltage'].fillna(df1['Voltage'].median(), inplace=True)
df1['Global_intensity'].fillna(df1['Global_intensity'].median(), inplace=True)
df1['Sub_metering_1'].fillna(df1['Sub_metering_1'].median(), inplace=True)
df1['Sub_metering_2'].fillna(df1['Sub_metering_2'].median(), inplace=True)
df1['Sub_metering_3'].fillna(df1['Sub_metering_3'].median(), inplace=True)

df1

df.columns

df.dropna(axis=1, inplace=True)

df.download as csv

# Assuming df is your DataFrame
df_iqr3.to_csv('dataframe.csv', index=False)

print("DataFrame has been saved as 'dataframe.csv'.")

len(df1)











































































import pandas as pd

df=pd.read_csv("project 27-01-2024.csv")

len(df)



df.info()

df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')  # Keep this line
df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')  # Change the format for Time column

df.dtypes

len(df)

df_iqr3.isnull().sum()

df_iqr3.duplicated().sum()

df.drop_duplicates(inplace=True)

import seaborn as sns

import seaborn as sns
import matplotlib.pyplot as plt

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(data=df_iqr3)
plt.xticks(rotation=90)  # Rotate labels by 90 degrees (vertical)
plt.show()

df.head()

df_iqr3

q1 = df_iqr3["Sub_metering_1"].quantile(0.25)
q3 = df_iqr3["Sub_metering_1"].quantile(0.75)
iqr = q3 - q1
ll = q1 - 1.5*iqr
ul = q3 + 1.5*iqr
print(ll,ul)

df_iqr4 = df_iqr3[df_iqr2["Sub_metering_1"].between(ll,ul)]

df_iqr3["Sub_metering_1"].skew()

df_iqr4["Sub_metering_1"].skew()

sns.boxplot(df_iqr["Global_active_power"])



columns = ["Global_active_power", "Global_reactive_power", "Voltage","Global_intensity","Sub_metering_1","Sub_metering_2"]  # List of columns you want to filter

filtered_dfs = {}
for column in columns:
    q1 = df[column].quantile(0.25)
    q3 = df[column].quantile(0.75)
    iqr = q3 - q1
    ll = q1 - 1.5 * iqr
    ul = q3 + 1.5 * iqr
    filtered_dfs[column] = df[df[column].between(ll, ul)]

# Example: Calculate skewness for each filtered column
for column, filtered_df in filtered_dfs.items():
    skewness = filtered_df[column].skew()
    print(f"Skewness of {column}: {skewness}")

filtered_dfs

pd.DataFrame()

df1.head()









df=pd.read_csv("dataframe 27-01-2025.csv")

df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')  # Keep this line
df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')  # Change the format for Time column

import numpy as np #numerical python
import pandas as pd #python dataframe
import statsmodels.api as sm
import matplotlib.pyplot as plt

# ... your existing code ...

# Assuming df is your DataFrame

# Convert 'Date' and 'Time' to numerical features
# Extract hour, minute, second from Time
df['Hour'] = df['Time'].dt.hour
df['Minute'] = df['Time'].dt.minute
df['Second'] = df['Time'].dt.second

# Extract day, month, year from Date
df['Day'] = df['Date'].dt.day
df['Month'] = df['Date'].dt.month
df['Year'] = df['Date'].dt.year

# Now, redefine X with the new numerical features
X = df[['Global_reactive_power', 'Voltage', 'Global_intensity',
        'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3',
        'Hour', 'Second', 'Day', 'Year']]
Y = df['Global_active_power']

# Add constant to X
X_1 = sm.add_constant(X)

# Fit the model
model = sm.OLS(Y, X_1).fit()
model.summary()

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)

!pip install mlxtend



from sklearn.linear_model import LinearRegression

classifier = LinearRegression()

from mlxtend.feature_selection import SequentialFeatureSelector as SFS
#Define Sequential Forward Selection (sfs)
sfs = SFS(classifier,
           k_features=11,
           forward=True,
           floating=False,
           cv = 0)
#Use SFS to select the top 6 features
sfs.fit(X, Y)

#Create a dataframe for the SFS results
df_SFS_results = pd.DataFrame(sfs.subsets_).transpose()
df_SFS_results

from mlxtend.feature_selection import SequentialFeatureSelector as SFS

# Get the number of features in X
num_features = X.shape[1]

# Ensure k_features is within the allowed range
k_features = min(10, num_features)  # Use minimum to ensure it's not greater than num_features

# Define Sequential Forward Selection (sfs)
sfs = SFS(classifier,
           k_features=k_features,  # Use the adjusted k_features value
           forward=True,
           floating=False,
           cv=0)

# Use SFS to select the top features
sfs.fit(X, Y)

# Create a dataframe for the SFS results
df_SFS_results = pd.DataFrame(sfs.subsets_).transpose()
df_SFS_results

from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs

fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')

plt.title('Sequential Forward Selection (w. StdErr)')
plt.grid()
plt.show()





lm = LinearRegression()

lm.fit(X_train,Y_train)

predictions = lm.predict( X_test)

ypred = model.predict(X_1)
print(ypred)

df['pred'] = ypred

df['error'] = Y - ypred
df.head()

import seaborn as sns

sns.distplot(df['error'])

from sklearn.metrics import mean_absolute_percentage_error

# Assuming X_test is your test set features

# Predict on the test set
Y_pred = model.predict(sm.add_constant(X_test)) # Add constant to X_test as well

# Calculate MAPE
mape = mean_absolute_percentage_error(Y_test, Y_pred)
print(f"MAPE: {mape}%")

import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error

# Assuming Y_test contains the actual values and Y_pred contains the predicted values

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(Y_test, Y_pred))

# Calculate MAE
mae = mean_absolute_error(Y_test, Y_pred)

print(f"RMSE: {rmse}")
print(f"MAE: {mae}")







import requests
import numpy as np
import pandas as pd
import io
from sklearn.model_selection import train_test_split # for splitting the data
from sklearn.metrics import mean_squared_error # for calculating the cost function
from sklearn.tree import DecisionTreeRegressor # for building the model

# Initializing the Decision Tree Regression model
model = DecisionTreeRegressor(random_state = 0)

# Fitting the Decision Tree Regression model to the data
model.fit(X_train, Y_train)



# Predicting the target values of the test set
y_pred = model.predict(X_test)

# RMSE (Root Mean Square Error)
rmse = float(format(np.sqrt(mean_squared_error(Y_test, y_pred)), '.3f'))
print("\nRMSE: ", rmse)

# Predicting the target values of the test set
y_pred_train = model.predict(X_train)

# RMSE (Root Mean Square Error)
rmse_train = float(format(np.sqrt(mean_squared_error(Y_train, y_pred_train)), '.3f'))
print("\nRMSE: ", rmse_train)

# Assuming X_test is your test set features

# Predict on the test set
#y_pred = model.predict(sm.add_constant(X_test)) # Add constant to X_test as well

# Calculate MAPE
mape = mean_absolute_percentage_error(Y_test, y_pred)
print(f"MAPE: {mape}%")









import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("dataframe 27-01-2025.csv")

df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')  # Keep this line
df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')  # Change the format for Time column



import numpy as np #numerical python
import pandas as pd #python dataframe
import statsmodels.api as sm
import matplotlib.pyplot as plt

# ... your existing code ...

# Assuming df is your DataFrame

# Convert 'Date' and 'Time' to numerical features
# Extract hour, minute, second from Time
df['Hour'] = df['Time'].dt.hour
df['Minute'] = df['Time'].dt.minute
df['Second'] = df['Time'].dt.second

# Extract day, month, year from Date
df['Day'] = df['Date'].dt.day
df['Month'] = df['Date'].dt.month
df['Year'] = df['Date'].dt.year

# Now, redefine X with the new numerical features
X = df[['Global_reactive_power', 'Voltage', 'Global_intensity',
        'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3',
        'Hour', 'Second', 'Day', 'Year']]
Y = df['Global_active_power']

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)

from sklearn.ensemble import RandomForestRegressor

rfcl = RandomForestRegressor(n_estimators = 100,oob_score=True)
rfcl = rfcl.fit(X_train, Y_train)

# Access OOB Score and Error
oob_score = rfcl.oob_score_
print("OOB Score:", oob_score)

oob_error = 1- rfcl.oob_score_
print("OOB Error:", oob_error)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error
import numpy as np

# Assuming X_train, Y_train, X_test, and Y_test are your datasets

# Initialize and train the RandomForestRegressor
#model = RandomForestRegressor(n_estimators=100, random_state=42)
#model.fit(X_train, Y_train)

# Predicting the target values of the training set
y_pred_train = model.predict(X_train)

# Predicting the target values of the test set
y_pred_test = model.predict(X_test)

# RMSE (Root Mean Square Error) for training set
rmse_train = float(format(np.sqrt(mean_squared_error(Y_train, y_pred_train)), '.3f'))
print("\nRMSE (Train): ", rmse_train)

# RMSE (Root Mean Square Error) for test set
rmse_test = float(format(np.sqrt(mean_squared_error(Y_test, y_pred_test)), '.3f'))
print("RMSE (Test): ", rmse_test)

# MSE (Mean Squared Error) for training set
mse_train = mean_squared_error(Y_train, y_pred_train)
print("MSE (Train): ", mse_train)

# MSE (Mean Squared Error) for test set
mse_test = mean_squared_error(Y_test, y_pred_test)
print("MSE (Test): ", mse_test)

# R^2 Score for training set
r2_train = r2_score(Y_train, y_pred_train)
print("R^2 (Train): ", r2_train)

# R^2 Score for test set
r2_test = r2_score(Y_test, y_pred_test)
print("R^2 (Test): ", r2_test)



# MAPE (Mean Absolute Percentage Error) for training set
mape_train = mean_absolute_percentage_error(Y_train, y_pred_train)
print("MAPE (Train): ", mape_train)

# MAPE (Mean Absolute Percentage Error) for test set
mape_test = mean_absolute_percentage_error(Y_test, y_pred_test)
print("MAPE (Test): ", mape_test)

# MAPE (Mean Absolute Percentage Error) for training set
mape_train = mean_absolute_percentage_error(Y_train, y_pred_train)
print("MAPE (Train): ", mape_train)

# MAPE (Mean Absolute Percentage Error) for test set
mape_test = mean_absolute_percentage_error(Y_test, y_pred_test)
print("MAPE (Test): ", mape_test)

# Adjusted R^2 for training set
n_train = len(Y_train)
p_train = X_train.shape[1]  # Get the number of columns using .shape[1]
adjusted_r2_train = 1 - (1 - r2_train) * (n_train - 1) / (n_train - p_train - 1)
print("Adjusted R^2 (Train): ", adjusted_r2_train)

# Adjusted R^2 for test set
n_test = len(Y_test)
p_test = X_test.shape[1]  # Get the number of columns using .shape[1]
adjusted_r2_test = 1 - (1 - r2_test) * (n_test - 1) / (n_test - p_test - 1)
print("Adjusted R^2 (Test): ", adjusted_r2_test)

























import pandas as pd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("dataframe 27-01-2025.csv")

df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')  # Keep this line
df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')  # Change the format for Time column



import numpy as np #numerical python
import pandas as pd #python dataframe
import statsmodels.api as sm
import matplotlib.pyplot as plt

# ... your existing code ...

# Assuming df is your DataFrame

# Convert 'Date' and 'Time' to numerical features
# Extract hour, minute, second from Time
df['Hour'] = df['Time'].dt.hour
df['Minute'] = df['Time'].dt.minute
df['Second'] = df['Time'].dt.second

# Extract day, month, year from Date
df['Day'] = df['Date'].dt.day
df['Month'] = df['Date'].dt.month
df['Year'] = df['Date'].dt.year

# Now, redefine X with the new numerical features
X = df[['Global_reactive_power', 'Voltage', 'Global_intensity',
        'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3',
        'Hour', 'Second', 'Day', 'Year']]
Y = df['Global_active_power']

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.3,random_state=0)

from sklearn.ensemble import GradientBoostingRegressor
gbcl = GradientBoostingRegressor(n_estimators = 200,random_state=1)
gbcl = gbcl.fit(X_train, Y_train)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error
import numpy as np

# Assuming X_train, Y_train, X_test, and Y_test are your datasets

# Initialize and train the RandomForestRegressor
model = RandomForestRegressor(n_estimators=100, random_state=42) # Uncomment this line and assign the model
model.fit(X_train, Y_train) # Uncomment this line and train the model

# Predicting the target values of the training set
y_pred_train = model.predict(X_train)

# Predicting the target values of the test set
y_pred_test = model.predict(X_test)

# ... (rest of your code)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error
import numpy as np

# Assuming X_train, Y_train, X_test, and Y_test are your datasets

# Initialize and train the RandomForestRegressor
#model = RandomForestRegressor(n_estimators=100, random_state=42)
#model.fit(X_train, Y_train)

# Predicting the target values of the training set
y_pred_train = gbcl.predict(X_train)

# Predicting the target values of the test set
y_pred_test = gbcl.predict(X_test)

# RMSE (Root Mean Square Error) for training set
rmse_train = float(format(np.sqrt(mean_squared_error(Y_train, y_pred_train)), '.3f'))
print("\nRMSE (Train): ", rmse_train)

# RMSE (Root Mean Square Error) for test set
rmse_test = float(format(np.sqrt(mean_squared_error(Y_test, y_pred_test)), '.3f'))
print("RMSE (Test): ", rmse_test)

# MSE (Mean Squared Error) for training set
mse_train = mean_squared_error(Y_train, y_pred_train)
print("MSE (Train): ", mse_train)

# MSE (Mean Squared Error) for test set
mse_test = mean_squared_error(Y_test, y_pred_test)
print("MSE (Test): ", mse_test)

# R^2 Score for training set
r2_train = r2_score(Y_train, y_pred_train)
print("R^2 (Train): ", r2_train)

# R^2 Score for test set
r2_test = r2_score(Y_test, y_pred_test)
print("R^2 (Test): ", r2_test)



# MAPE (Mean Absolute Percentage Error) for training set
mape_train = mean_absolute_percentage_error(Y_train, y_pred_train)
print("MAPE (Train): ", mape_train)

# MAPE (Mean Absolute Percentage Error) for test set
mape_test = mean_absolute_percentage_error(Y_test, y_pred_test)
print("MAPE (Test): ", mape_test)

# MAPE (Mean Absolute Percentage Error) for training set
mape_train = mean_absolute_percentage_error(Y_train, y_pred_train)
print("MAPE (Train): ", mape_train)

# MAPE (Mean Absolute Percentage Error) for test set
mape_test = mean_absolute_percentage_error(Y_test, y_pred_test)
print("MAPE (Test): ", mape_test)

# Adjusted R^2 for training set
n_train = len(Y_train)
p_train = X_train.shape[1]  # Get the number of columns using .shape[1]
adjusted_r2_train = 1 - (1 - r2_train) * (n_train - 1) / (n_train - p_train - 1)
print("Adjusted R^2 (Train): ", adjusted_r2_train)

# Adjusted R^2 for test set
n_test = len(Y_test)
p_test = X_test.shape[1]  # Get the number of columns using .shape[1]
adjusted_r2_test = 1 - (1 - r2_test) * (n_test - 1) / (n_test - p_test - 1)
print("Adjusted R^2 (Test): ", adjusted_r2_test)









import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neural_network import MLPRegressor

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

X_train = sc.fit_transform(X_train)

X_test = sc.transform(X_test)

clf = MLPRegressor(hidden_layer_sizes=(100), max_iter=5000,
                     solver='sgd', verbose=True,random_state=21,tol=0.000000001)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error
import numpy as np

# Assuming X_train, Y_train, X_test, and Y_test are your datasets

# Initialize and train the RandomForestRegressor
#model = RandomForestRegressor(n_estimators=100, random_state=42)
#model.fit(X_train, Y_train)

# Predicting the target values of the training set
y_pred_train = clf.predict(X_train)

# Predicting the target values of the test set
y_pred_test = clf.predict(X_test)

# RMSE (Root Mean Square Error) for training set
rmse_train = float(format(np.sqrt(mean_squared_error(Y_train, y_pred_train)), '.3f'))
print("\nRMSE (Train): ", rmse_train)

# RMSE (Root Mean Square Error) for test set
rmse_test = float(format(np.sqrt(mean_squared_error(Y_test, y_pred_test)), '.3f'))
print("RMSE (Test): ", rmse_test)

# MSE (Mean Squared Error) for training set
mse_train = mean_squared_error(Y_train, y_pred_train)
print("MSE (Train): ", mse_train)

# MSE (Mean Squared Error) for test set
mse_test = mean_squared_error(Y_test, y_pred_test)
print("MSE (Test): ", mse_test)

# R^2 Score for training set
r2_train = r2_score(Y_train, y_pred_train)
print("R^2 (Train): ", r2_train)

# R^2 Score for test set
r2_test = r2_score(Y_test, y_pred_test)
print("R^2 (Test): ", r2_test)



# MAPE (Mean Absolute Percentage Error) for training set
mape_train = mean_absolute_percentage_error(Y_train, y_pred_train)
print("MAPE (Train): ", mape_train)

# MAPE (Mean Absolute Percentage Error) for test set
mape_test = mean_absolute_percentage_error(Y_test, y_pred_test)
print("MAPE (Test): ", mape_test)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error
import numpy as np

# Assuming X_train, Y_train, X_test, and Y_test are your datasets

# Initialize and train the RandomForestRegressor
#model = RandomForestRegressor(n_estimators=100, random_state=42)
#model.fit(X_train, Y_train)

# Fit the MLPRegressor model before predicting
clf.fit(X_train, Y_train) # This line is added to train the model

# Predicting the target values of the training set
y_pred_train = clf.predict(X_train)

# Predicting the target values of the test set
y_pred_test = clf.predict(X_test)

# RMSE (Root Mean Square Error) for training set
rmse_train = float(format(np.sqrt(mean_squared_error(Y_train, y_pred_train)), '.3f'))
print("\nRMSE (Train): ", rmse_train)

# RMSE (Root Mean Square Error) for test set
rmse_test = float(format(np.sqrt(mean_squared_error(Y_test, y_pred_test)), '.3f'))
print("RMSE (Test): ", rmse_test)

# MSE (Mean Squared Error) for training set
mse_train = mean_squared_error(Y_train, y_pred_train)
print("MSE (Train): ", mse_train)

# MSE (Mean Squared Error) for test set
mse_test = mean_squared_error(Y_test, y_pred_test)
print("MSE (Test): ", mse_test)

# R^2 Score for training set
r2_train = r2_score(Y_train, y_pred_train)
print("R^2 (Train): ", r2_train)

# R^2 Score for test set
r2_test = r2_score(Y_test, y_pred_test)
print("R^2 (Test): ", r2_test)



# MAPE (Mean Absolute Percentage Error) for training set
mape_train = mean_absolute_percentage_error(Y_train, y_pred_train)
print("MAPE (Train): ", mape_train)

# MAPE (Mean Absolute Percentage Error) for test set
mape_test = mean_absolute_percentage_error(Y_test, y_pred_test)
print("MAPE (Test): ", mape_test)

# Adjusted R^2 for training set
n_train = len(Y_train)
p_train = X_train.shape[1]  # Get the number of columns using .shape[1]
adjusted_r2_train = 1 - (1 - r2_train) * (n_train - 1) / (n_train - p_train - 1)
print("Adjusted R^2 (Train): ", adjusted_r2_train)

# Adjusted R^2 for test set
n_test = len(Y_test)
p_test = X_test.shape[1]  # Get the number of columns using .shape[1]
adjusted_r2_test = 1 - (1 - r2_test) * (n_test - 1) / (n_test - p_test - 1)
print("Adjusted R^2 (Test): ", adjusted_r2_test)